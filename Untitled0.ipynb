{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNA38BNKrmI1R4e/6zb8JKP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vishal3347/Data-driven-innovation/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I54c7OsTP2kG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import joblib  # Import joblib for saving the encoder\n",
        "\n",
        "# Read and inspect the dataset\n",
        "metadata = pd.read_csv(r'C:\\Users\\visha\\Downloads\\archive\\filtered_HAM10000_metadata.csv')\n",
        "print(metadata.head())\n",
        "\n",
        "# Add full image path to the DataFrame\n",
        "metadata['image_path'] = metadata['image_id'].apply(\n",
        "    lambda x: os.path.join(r'C:\\Users\\visha\\Downloads\\archive\\HAM10000_images_part_1', f\"{x}.jpg\"))\n",
        "\n",
        "# Visualize class distribution\n",
        "sns.countplot(x='dx', data=metadata)\n",
        "plt.show()\n",
        "\n",
        "# Encode the labels (dx) into numerical values\n",
        "label_encoder = LabelEncoder()\n",
        "metadata['label'] = label_encoder.fit_transform(metadata['dx'])\n",
        "\n",
        "# Save the LabelEncoder to a file\n",
        "joblib.dump(label_encoder, 'label_encoder.pkl')  # Save the entire encoder object\n",
        "\n",
        "# Optionally, save the classes to a .npy file (if you want to use them separately)\n",
        "np.save('label_encoder_classes.npy', label_encoder.classes_)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_data, test_data = train_test_split(metadata, test_size=0.2, stratify=metadata['label'], random_state=42)\n",
        "\n",
        "# Preprocessing function for images\n",
        "def preprocess_image(image_path, target_size=(150, 150)):\n",
        "    img = load_img(image_path, target_size=target_size)  # Load and resize the image\n",
        "    img = img_to_array(img) / 255.0  # Convert image to array and normalize pixel values\n",
        "    return img\n",
        "\n",
        "# Process training and testing images\n",
        "X_train = np.array([preprocess_image(img) for img in train_data['image_path']])\n",
        "X_test = np.array([preprocess_image(img) for img in test_data['image_path']])\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y_train = to_categorical(train_data['label'])\n",
        "y_test = to_categorical(test_data['label'])\n",
        "\n",
        "# Check image dimensions\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "\n",
        "# Build a CNN model\n",
        "model = Sequential()\n",
        "\n",
        "# Convolutional layer 1\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Convolutional layer 2\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Flatten the output of the convolutional layers\n",
        "model.add(Flatten())\n",
        "\n",
        "# Fully connected layer\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))  # Dropout to prevent overfitting\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(len(metadata['label'].unique()), activation='softmax'))  # The number of classes\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Summary of the model\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test accuracy: {test_accuracy * 100:.2f}%')\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "plt.plot(history.history['accuracy'], label='train accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val accuracy')\n",
        "plt.title('Model accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot training and validation loss\n",
        "plt.plot(history.history['loss'], label='train loss')\n",
        "plt.plot(history.history['val_loss'], label='val loss')\n",
        "plt.title('Model loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Save the trained model\n",
        "model.save('skin_cancer_classifier.h5')\n",
        "\n",
        "# Loading the saved LabelEncoder\n",
        "loaded_label_encoder = joblib.load('label_encoder.pkl')  # Load the saved LabelEncoder\n",
        "\n",
        "# Example: Use the loaded encoder to transform labels\n",
        "new_label = loaded_label_encoder.transform(['nv'])  # Example label transformation\n",
        "print(new_label)\n",
        "\n",
        "# Example: Use the loaded encoder to decode labels\n",
        "decoded_label = loaded_label_encoder.inverse_transform([0])  # Example decoding\n",
        "print(decoded_label)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rEFaqCBmQFre"
      }
    }
  ]
}